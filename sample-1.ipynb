{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf().setAppName(\"upsell-fortnight\")\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.executor.memory', '4G')\n",
    "        .set('spark.driver.memory', '8G')\n",
    "        .set('spark.driver.maxResultSize', '8G')\n",
    "         .set('spark.debug.maxToStringFields', '200'))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "#sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "sqlcontext = SQLContext(sc)\n",
    "sqlcontext.sql(\"set spark.sql.shuffle.partitions=10\")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier,MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.sql.types import _infer_schema, IntegerType, DateType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler, CountVectorizer\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "today = (date.today())\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\" face=\"calibri\">\n",
    "    <p><b>DATA & ITEM</b></p>\n",
    "    <p></p>\n",
    "</font>\n",
    "\n",
    "<font size= \"3\" color='blue' face=\"verdana\">\n",
    "    <p><i> 1. need the data  and the Item at this stage.</i> </p>\n",
    "   <p><i> 2. Join the two (inner ?) by \"\" to get corresponding details for an item from Item Master </i></p>\n",
    "   <p><i> 3. have the number, number (and other broader categories), units and other details</i> </p>\n",
    "   <p><i> 4. create a fortnight feature which denotes a single integer for every fortnight till date.</i></p>\n",
    "   <p><i> 5. create/train an ML model for every item. For one item, the train data will be for every single customer that bought (or didn't) that item.</i></p>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> Convert sales excel files to pyspark through Pandas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> Save CSVs as parquet </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = sqlcontext.read.parquet('<DATA>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\" size=\"4\"><p>Incoming item master will be an Excel - convert it to spark df</p><p>Change: couldn't read xls format</p></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = sqlcontext.read.csv('IM.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('item')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM.write.parquet('item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> Creating Fortnights and saving them separately <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateFortnight(salesData:\"pyspark.sql.dataframe.Dataframe\", today:\"string\", dayGap:\"Integer\"):\n",
    "    \n",
    "    #sales_data = salesData.withColumn('OnlyDate',F.split( F.date_format(F.to_date(F.col(\"TRANSACTION_DATE\"), \"MM/dd/yy\"), \"yyyy-MM-dd hh:mm:ss\"),\" \")\\\n",
    "    #                                .getItem(0)).drop('TRANSACTION_DATE')\n",
    "    \n",
    "    sales_data = salesData.withColumn('OnlyDate',F.split( F.col(\"TRANSACTION_DATE\"),\" \")\\\n",
    "                                    .getItem(0)).drop('TRANSACTION_DATE')\n",
    "    #sales_data.show()\n",
    "    maxDateLTtoday = sales_data.where( F.col(\"OnlyDate\")<=F.lit(str(today)) ).select(F.max(\"OnlyDate\").alias('mD')).collect()[0]\n",
    "    \n",
    "    if(maxDateLTtoday.mD):\n",
    "        tmpDate = date(int(maxDateLTtoday.mD.split('-')[0]),int(maxDateLTtoday.mD.split('-')[1]),int(maxDateLTtoday.mD.split('-')[2]))\n",
    "    else:\n",
    "        return \"There is no data before the given date\"\n",
    "    \n",
    "    tmpDateGap = tmpDate - timedelta(days = dayGap)\n",
    "    \n",
    "    salesDataBeforeToday = sales_data.filter( (F.col(\"OnlyDate\")<=(F.lit(str(tmpDate)))) & (F.col(\"OnlyDate\")>(F.lit(str(tmpDateGap)))) )\n",
    "    \n",
    "    ct=1\n",
    "    while len(salesDataBeforeToday.head(1))>0:\n",
    "        \n",
    "        #This can be any number but restricting data to past 24 fortnights\n",
    "        if(ct==24):break\n",
    "        \n",
    "        salesDataBeforeToday = salesDataBeforeToday.withColumn('fortnight',F.lit(ct))\n",
    "        salesDataBeforeToday = salesDataBeforeToday.where(F.col('UNITS_NET')>0)\n",
    "        \n",
    "        salesDataBeforeToday.write.parquet('Sales_data_with_latest_fortnights/'+str(ct))\n",
    "        \n",
    "        print(\"Time period: \"+str(tmpDateGap)+\" To \"+str(tmpDate))\n",
    "        \n",
    "        tmpDate = tmpDateGap\n",
    "        tmpDateGap = tmpDate - timedelta(days = dayGap)\n",
    "        \n",
    "        salesDataBeforeToday = sales_data.filter( (F.col(\"OnlyDate\")<=(F.lit(str(tmpDate)))) & (F.col(\"OnlyDate\")>(F.lit(str(tmpDateGap)))) )\n",
    "        \n",
    "        ct+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('S_with_latest_fortnights')\n",
    "time.sleep(5)\n",
    "CreateFortnight(sales_data, date(2019,1,31), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> Get Item and set the product value field <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_master = sqlcontext.read.parquet('item_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This field will be used for training\n",
    "product_value = 'abcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_master = item_master.withColumnRenamed(product_value,'product_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_master.count()\n",
    "#item_master.where(F.col('product_value').isNull()).count()\n",
    "#i = item_master.groupBy('ITEM_NO').agg(F.collect_set('product_value').alias('listt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_master = item_master.orderBy('product_value',ascending=False).dropDuplicates(subset=['ITEM_NO'])\\\n",
    ".withColumn('product_value',F.when(F.col('product_value').isNull(),F.lit(F.col('ITEM_NO'))).otherwise(F.lit(F.col('product_value'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> \n",
    "    <p>Read the Sale Data</p>\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALES = sqlcontext.read.parquet('Sales_data_with_latest_fortnights/**/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALES = SALES.withColumn('year',F.split(SALES['OnlyDate'],\"-\").getItem(0))\n",
    "SALES = SALES.withColumn('month',F.split(SALES['OnlyDate'],\"-\").getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALES.write.partitionBy('year','month','fortnight').parquet(\"SALES_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> \n",
    "    <p>Connect to item master</p>\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALES.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master = SALES.join(item_master,'ITEM_NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> \n",
    "    <p>Save it</p>\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('sales_item_master')\n",
    "time.sleep(5)\n",
    "sales_item_master.write.parquet('sales_item_master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='4'> \n",
    "    <p>Fortnight as features</p>\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master = sqlcontext.read.parquet('sales_item_master')\n",
    "shutil.rmtree('sales_features_fortnight_only')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master_ = sales_item_master\\\n",
    ".withColumn('fortnight',F.col('fortnight').cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master_ = sales_item_master_.select('*')\\\n",
    ".groupBy('CUST_SHIP_TO_NO')\\\n",
    ".agg(F.collect_set('fortnight').alias('fortnight_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_item_master_.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_item_master_ = sales_item_master_.withColumn('fortnight_array',F.array(F.col('fortnight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_fortnight = CountVectorizer(inputCol='fortnight_array', outputCol='fortnight_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_f = cv_fortnight.fit(sales_item_master_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_item_master_ = cv_f.transform(sales_item_master_).drop('fortnight_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_item_master_.write.parquet('customer_fortnights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4' color='green'> \n",
    "      <p>End of this script, below is all testing </p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_item_master_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_item_master_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data1 = sales_data.withColumn('FF',F.split( F.date_format(F.to_date(F.col(\"TRANSACTION_DATE\"), \"MM/dd/yy\"), \"yyyy-MM-dd hh:mm:ss\"),\" \")\\\n",
    "#                                    .getItem(0))\\\n",
    "#.withColumn(\"year\",F.year('FF')).withColumn(\"month\",F.month('FF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data11 = sales_data1.withColumn('FFF',F.when( (F.split(sales_data1['FF'],\"-\").getItem(2))<=15,\n",
    "#                                                   ( str(F.split(sales_data1['FF'],\"-\").getItem(0))+str(\"_15\") ))\\\n",
    "#                                      .otherwise( str(F.split(sales_data1['FF'],\"-\").getItem(0))+str(\"_30\")))\n",
    "\n",
    "#sales_data11 = sales_data1.withColumn('FFF',F.when( (F.split(sales_data1['FF'],\"-\").getItem(2))<=15,\n",
    "#                                                   (F.concat( F.col('year'),F.lit(\"_\"),F.col('month'),F.lit(\"_15\") )))\\\n",
    "#                                      .otherwise( F.concat( F.col('year'),F.lit(\"_\"),F.col('month'),F.lit(\"_30\") )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data = sales_data11.drop('TRANSACTION_DATE','FF','year','month').withColumnRenamed('FFF','fortnight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data = sales_data.where(F.col('UNITS_NET')>0).drop('TRANSACTION_DATE').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
